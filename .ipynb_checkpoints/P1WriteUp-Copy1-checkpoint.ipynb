{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Lane Lines on the Road"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project,I used some OpenCV APIs to identify lane lines on the road.The goal is piece together a pipeline to decet the line segments in the image,then connect them and draw them onto the image for display(show below).\n",
    "\n",
    "<figure>\n",
    " <img src=\"test_images_output/Hough_of_solidYellowLeft.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> detect line segments</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n",
    "<figure>\n",
    " <img src=\"test_images_output/Extrapolating of solidYellowLeft.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> connect and extrapolate line segments</p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following tools are used:\n",
    "* color selection\n",
    "* region of interest selection\n",
    "* Gaussian smoothing\n",
    "* Canny Edge Detection\n",
    "* Hough Tranform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in a test image\n",
    "\n",
    "<figure>\n",
    " <img src=\"test_images/solidYellowCurve.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    "</figure>\n",
    "\n",
    "\n",
    "The upper part of the image is the sky and the lower part is the road. On the left side of the road is a solid yellow line and on the right are white line segments.I need to draw just one line for the left side of the lane and one for the right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Selection\n",
    "\n",
    "This image is in RGB color space.In order to better detect yellow line and white line,I need to convent the image from RGB space to HSV space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # yellow theshold\n",
    "    lower_yellow = np.array([20,80,50])\n",
    "    upper_yellow = np.array([40,255,255])\n",
    "    \n",
    "    # white theshold\n",
    "    lower_white = np.array([0,0,220])\n",
    "    upper_white = np.array([180,25,255])\n",
    "    \n",
    "    #convent image from RGB color space to HSV color space\n",
    "    hsv_img = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # select yellow and white\n",
    "    yellow_mask_img = cv2.inRange(hsv_img,lower_yellow,upper_yellow)\n",
    "    white_mask_img = cv2.inRange(hsv_img,lower_white,upper_white)\n",
    "    \n",
    "    #conbine yellow and white\n",
    "    mask_img = cv2.bitwise_or(yellow_mask_img,white_mask_img)\n",
    "    \n",
    "    # Bitwise-AND mask and original image for showing\n",
    "    color_mask_img = cv2.bitwise_and(img,img, mask= mask_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<figure>\n",
    " <img src=\"writeup/Color_selection.png\" style=\"zoom:100%\" alt=\"Center\" />\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region of Interest Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the color selection, most of the content that is not related to the road line has been filtered out. Assuming the position of the camera is fixed, the road line will often appear in the same region.It's very important to find the region that I would like to retain for my color selection, while masking everything else out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # get size of image\n",
    "    ysize = image.shape[0]\n",
    "    xsize = image.shape[1]\n",
    "\n",
    "    # edge points of interest regions\n",
    "    left_bottom = [0,ysize]\n",
    "    right_bottom = [xsize,ysize]\n",
    "    left_apex =[int(0.45*xsize),int(0.62*ysize)]\n",
    "    right_apex = [int(0.58*xsize),int(0.62*ysize)]\n",
    "    \n",
    "    #region of interest\n",
    "    vertices = np.array([[left_bottom,left_apex,right_apex, right_bottom]], dtype=np.int32)\n",
    "    region_img = region_of_interest(img,vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<figure>\n",
    " <img src=\"writeup/Region_selection.png\" style=\"zoom:100%\" alt=\"Center\" />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Smoothing and Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With edge detectionï¼Œthe goal is to identify the boundaries of an object in an image.Some OpenCV functions used are as follow:\n",
    "\n",
    "* `cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)`for Grayscale transforming\n",
    "* `cv2.GaussianBlur(img,(kernel_size,kernel_size),0)` for Gaussian Smoothing\n",
    "* `cv2.Canny(img,low_threshold,high_threshold)` for Canny transforming\n",
    "\n",
    "**Note:**\n",
    "* the kernel_size for Gaussian Smoothing must be any odd number.The bigger the value is,the more blurred the image becomes.I tried 3,5,7,9,11 and finally chosed 9.\n",
    "* low_threshold and high_threshold for Canny are the thresholds for edge detection.As far as a ratio of lew_threshold and high_threshold ,John Canny himself recommended a low to high ratio of 1:2 or 1:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"writeup/Canny_edge_detection.png\" style=\"zoom:100%\" alt=\"Center\" />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Tranform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hough Transform is just the conversion from image space to Hough space.I used an OpenCV function called HoughLineP to find the lane lines in the image.\n",
    "\n",
    "`lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)`\n",
    "\n",
    "\n",
    "* rho = 1            :distance resolution in pixels of the Hough grid\n",
    "* theta = np.pi/180  :angular resolution in radians of the Hough grid\n",
    "* threshold = 30     :minimum number of votes (intersections in Hough grid cell)\n",
    "* min_line_length = 20 :minimum number of pixels making up a line\n",
    "* max_line_gap = 250   :maximum gap in pixels between connectable line segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"writeup/Canny_and_Hough.png\" style=\"zoom:100%\" alt=\"Center\" />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the draw_lines() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have deceted the line segments in the image.Then,I need to connect them and draw them onto the image for display.To do this, I need improve the draw_lines() function.\n",
    "\n",
    "First,I calculate the slope of each line segments separately.If the slop is greater than zero,it belongs to the right part,otherwise to the left part. Because the y coordinate is reversed.\n",
    "\n",
    "Second,I average the points and slopes on the left.Then,I extrapolate to the top and bottom of the lane.I do the same thing on the right.\n",
    "\n",
    "Then,I use cv2.line to draw left line and right line on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10,extrapolate = False):\n",
    "    left_point = []\n",
    "    right_point = []\n",
    "    left_slope = []\n",
    "    right_slope = []\n",
    "\n",
    "    if lines is not None:\n",
    "\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "\n",
    "                # calculate slope\n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "\n",
    "                if slope < -0.3: # left lines,filter out the horizontal lines\n",
    "\n",
    "                    left_point.append((x1,y1))\n",
    "                    left_point.append((x2,y2))\n",
    "                    left_slope.append(slope)\n",
    "\n",
    "                elif slope > 0.3:# right lines,filter out the horizontal lines\n",
    "\n",
    "                    right_point.append((x1,y1))\n",
    "                    right_point.append((x2,y2))\n",
    "                    right_slope.append(slope)\n",
    "\n",
    "        # average postion all points of left and right,average slope\n",
    "        left_point = np.array(left_point)\n",
    "        right_point = np.array(right_point)\n",
    "        left_slope = np.array(left_slope)\n",
    "        right_slope = np.array(right_slope)\n",
    "\n",
    "        if len(left_point):\n",
    "\n",
    "\n",
    "            # Average the left points  and slope\n",
    "            x = np.average(left_point[:,0])\n",
    "            y = np.average(left_point[:,1])\n",
    "            left_slope = np.average(left_slope)\n",
    "\n",
    "            # calculate tow points of left line\n",
    "            left_top = (int(0.62 * img.shape[0]) - y)/left_slope + x\n",
    "            left_bottom = (img.shape[0] - y) / left_slope + x\n",
    "\n",
    "            #draw left line\n",
    "            cv2.line(img,(int(left_bottom),img.shape[0]),(int(left_top),int(0.62 * img.shape[0])),color,thickness)  \n",
    "\n",
    "\n",
    "        if len(right_point):\n",
    "\n",
    "            # Average the right points  and slope\n",
    "            x = np.average(right_point[:,0])\n",
    "            y = np.average(right_point[:,1])\n",
    "            right_slope = np.average(right_slope)\n",
    "\n",
    "            # calculate tow points of right line\n",
    "            right_top = (int(0.62 * img.shape[0])  - y) / right_slope + x\n",
    "            right_bottom = (img.shape[0] - y) / right_slope + x\n",
    "\n",
    "            # draw right line\n",
    "            cv2.line(img,(int(right_bottom),img.shape[0]),(int(right_top),int(0.62 * img.shape[0])),color,thickness)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"writeup/Hough_transform_extrapolate.png\" style=\"zoom:100%\" alt=\"Center\" />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
